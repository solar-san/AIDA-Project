{"cells":[{"cell_type":"markdown","metadata":{},"source":["---\n","title: \"Artificial Intelligence and Data Analytics\"\n","subtitle: \"Reinforcement Learning: Monte Carlo Tree Search\"\n","author: \"solar-san\"\n","date-modified: \"2023-09-26\"\n","format:\n","  html:\n","    theme: github\n","    toc: true\n","    toc-location: left\n","    fig-align: center\n","    fig-width: 8\n","    fig-height: 8\n","    html-math-method: katex\n","    code-overflow: scroll\n","    code-copy: hover\n","    highlight-style: gruvbox\n","    citations-hover: true\n","    footnotes-hover: true\n","    header-includes: |\n","      <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n","      <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n","      <link href=\"https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Fira+Code&display=swap\" rel=\"stylesheet\">\n","mainfont: \"Atkinson Hyperlegible\"\n","monofont: 'Fira Code'\n","---"]},{"cell_type":"markdown","metadata":{},"source":["![](header/AIDA-Project_header.png)"]},{"cell_type":"markdown","metadata":{"id":"-qapEKTAYY2I"},"source":["# Agent Carletto and the Tree Search\n","\n","The following notebook contains all the code and a textual explanation of the Monte Carlo Tree Search algorithm implementation, aiming to obtain a challenging AI player, able to evaluate the state of the game and select the best move at each turn, having perfect knowledge of all the other players' cards.\n","\n","What is a Monte Carlo Tree Search?\n","\n","First of all, the term _Monte Carlo_ refers to a set of _methods_:\n","\n","> Monte Carlo methods may be thought of as a collection of computational techniques for the (usually approximate) solution of mathematical problems, which make fundamental use of random samples.\n","\n","The slides contain a detailed explanation of the Tree Search algorithm implementation. Before introducing the code, a small section of imports and helper functions.\n","\n","## Import setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2557,"status":"ok","timestamp":1693230347930,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"kW3CXFEgYY2M","outputId":"97636546-3b83-4808-c0af-a95012ae1b7e"},"outputs":[],"source":["import copy\n","import itertools\n","import typing\n","import random\n","\n","import Greedy_MOD\n","import Intermediate\n","\n","from Greedy_MOD import values\n","\n","from pandas import NA\n","from pandas._libs.missing import NAType"]},{"cell_type":"markdown","metadata":{"id":"8tuXxe5i7L1R"},"source":["## Helper Functions and Variables"]},{"cell_type":"markdown","metadata":{"id":"eT2lzfCqYQ9_"},"source":["The `print_attributes` function will help debugging the code: for each programmer-defined class, it prints all its attributes, allowing to monitor the execution of the program.\n","\n","While it has been extensively used for coding, it has been (almost) completely removed from this version of the notebook."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1693230347930,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"s11Xqj8n7L1S"},"outputs":[],"source":["def print_attributes(obj):\n","    '''\n","    Traverses all attributes of an object and prints their name and its corresponding value.\n","    '''\n","    for attr in vars(obj):\n","        print(attr, getattr(obj, attr))"]},{"cell_type":"markdown","metadata":{"id":"xCEyzjxiH793"},"source":["### Test variables\n","\n","This section contains a list of variables and game scenarios which will be used to travel along all the classes and methods to explain how we engineered the algorithm, allowing the computer to know what a Scopone game is, what is a legal move, what is a card, and, most importantly, how to learn and execute the move that achieves the best score."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693230347930,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"IdkJ-APm7L1S"},"outputs":[],"source":["PlayerPositions = [0, 1, 2, 3]"]},{"cell_type":"markdown","metadata":{"id":"WDAnOK1MUJoA"},"source":["#### `test1`\n","\n","This will be the main game scenario, to which most (if not all) methods will be applied to show how each class and method works and how to structure them properly.\n","\n","It is a quite complex situation: the AI player starts and can choose between a _single pick_ or different _combinations_.\n","\n","To summarise:\n","- 3 turns to the end.\n","- Multiple combinations available, as well as single picks.\n","- Montecarlo starts.\n","\n","In this first definition of a game scenario, we will continue by using the `tuple` to represent a _card_ and the _list of tuple_ for a _set of cards_.\n","\n","We need to ask ourself a question: how is a _scopone_ game defined? We can model it as a _succession of __states___ and every state is perfectly known if the following informations are available:\n","\n","1. Player position.\n","2. Cards on the table.\n","3. Cards in each players' hand.\n","4. Each team scores.\n","\n","By combining these informations we have all we need to know to give each player all he/it needs to decide what card to play."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693230347930,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"pmX9kttuH794"},"outputs":[],"source":["test1_Table = [\n","    (1, 1),\n","    (4, 2),\n","    (9, 4),\n","    (6, 3)\n","]\n","test1_PlayersCards = {\n","    0: [(1, 2), (10, 4), (5, 3)],\n","    1: [(2, 2), (9, 3), (8, 3)],\n","    2: [(1, 3), (9, 2), (4, 3)],\n","    3: [(10, 1), (10, 3), (3, 3)]\n","}\n","test1_Team = \"Hand\"\n","test1_TeamScores= {\n","    \"Hand\": 500,\n","    \"Deck\": 500\n","}"]},{"cell_type":"markdown","metadata":{"id":"iOXieuDoUJoA"},"source":["### `test2`\n","\n","This test scenario is for _debug_ purposes: if there is a _scopa_ on the table, it is always the best choice to make it.\n","\n","We wanted to be sure that the AI was able to recognise this opportunity and to compute the resulting score correctly.\n","\n","To summarise:\n","\n","- Same as `test1`, but with a possible _scopa_ to be made"]},{"cell_type":"markdown","metadata":{"id":"K2UZn_1oUJoB"},"source":["### `test3`\n","\n","This is a completely different game situation for our AI player: it is the _last_ to play and there are _no cards_ on the table.\n","\n","This would be difficult even for a competent human player, because the risk of exposing his team to a _scopa_ is very high: therefore, it is a very ambiguous situation.\n","\n","To summarise:\n","\n","- Last turn, _Deck_ team.\n","- Montecarlo is the last one to play.\n","- No cards on the table."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693230347930,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"_N9Rhvh5UJoB"},"outputs":[],"source":["test3_Table = [\n","]\n","test3_PlayersCards = {\n","    0: [(1, 2), (10, 4), (5, 3)],\n","    1: [(2, 2), (9, 3), (8, 3)],\n","    2: [(1, 1), (9, 2), (4, 3)],\n","    3: [(10, 1), (10, 3), (3, 3), (7, 3)]\n","}\n","test3_PlayerPosition = 3\n","test3_Team = \"Deck\"\n","test3_TeamScores= {\n","    \"Hand\": 500,\n","    \"Deck\": 500\n","}"]},{"cell_type":"markdown","metadata":{"id":"BVaqUBH8UJoB"},"source":["### `test4`, `test5`, `test6`\n","\n","All these test scenarios have been used only for _debugging_ purposes: they simulate a specific scenario in the _game tree_ in which the code was not working properly, allowing to analyse it in a detailed way."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693230347931,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"W9FFWLNdUJoB"},"outputs":[],"source":["test4_Table = [\n","    (5, 3),\n","    (6, 4),\n","    (9, 1)\n","]\n","\n","test4_PlayersCards = {\n","    0: [(1, 2)],\n","    1: [(7, 2)],\n","    2: [(0, 1)],\n","    3: [(10, 1), (2, 3)]\n","}\n","test4_PlayerPosition = 3\n","test4_Team = \"Deck\"\n","test4_TeamScores= {\n","    \"Hand\": 500,\n","    \"Deck\": 500\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":74,"status":"ok","timestamp":1693230348634,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"M8WjZVEJStyP"},"outputs":[],"source":["test5_Table = [\n","    (10, 3),\n","    (1, 2)\n","]\n","\n","test5_PlayersCards = {\n","    0: [(1, 2)],\n","    1: [(2, 2), (8, 3)],\n","    2: [(9, 2), (4, 3)],\n","    3: [(10, 1), (3, 3)]\n","}\n","test5_PlayerPosition = 0\n","test5_Team = \"Hand\"\n","test5_TeamScores= {\n","    \"Hand\": 1584,\n","    \"Deck\": 520\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":74,"status":"ok","timestamp":1693230348634,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"x09RJTUjStyP"},"outputs":[],"source":["test6_Table = [\n","    (6, 3),\n","    (10, 3)\n","]\n","\n","test6_PlayersCards =  {\n","    0: [(5, 3)],\n","    1: [(2, 2), (8, 3)],\n","    2: [(1, 3), (9, 2)],\n","    3: [(10, 1), (3, 3)]\n","}\n","\n","test6_PlayerPosition = 0\n","test6_Team = \"Hand\"\n","test6_TeamScores= {\n","    \"Hand\": 570,\n","    \"Deck\": 520\n","}"]},{"cell_type":"markdown","metadata":{"id":"dQthr2BhYY2N"},"source":["## Interfaces\n","\n","> Interfaces are abstract generic classes that contains the required blocks to implement a Monte Carlo Tree Search-based AI player.\n","\n","Building on Di Palma, S. \"_Monte Carlo Tree Search algorithms applied to the card game Scopone_\" (2014), we coded this interfaces to have a fundamental _architecture_ that allowed us to keep track of all the blocks needed for the algorithm to work.\n","\n","From a quick glance, it is clear that the Monte Carlo Tree Search is a whole different class of AI, compared to the `Greedy` and `Intermediate` ruled-based AIs, because exploring the game tree requires: on the one hand, to know everything about the current scenario (_cards, hands, table, score, etc._), and, on the other hand, to _simulate_ a reasonable strategy for every other player, on the same team and on the other.\n","\n","This implies that we need two fundamental classes: a class that represents a _game state_, `IGameState`, and a class to represent what is the other player's strategies and to simulate their moves, `IGameMove`.\n","\n","Moreover, we made an architectural choice: each node in the tree will be represented by an instance of the class `IGameState`: therefore, this class will also contain methods and utilities necessary to perform the tree search (e.g.: since each node in the tree has to be _hashable_, the `IGameState` class has a `__hash__` method to achieve this)."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":73,"status":"ok","timestamp":1693230348634,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"Bnu0lv7cYY2O"},"outputs":[],"source":["class IGameState(object):\n","    '''\n","    The GameState wholly defines the game at a given moment.\n","\n","    Moreover, passes informations from the current game state to the following one.\n","    '''\n","\n","    def __init__(self) -> None:\n","        pass\n","\n","    def __hash__(self) -> int:\n","        '''\n","        GameStates also play the role of nodes in the tree building. Nodes should be hashable.\n","        '''\n","        return 19\n","\n","    def GetAvailableMoves(\n","        self\n","    ):\n","        raise NotImplementedError()\n","\n","    def ApplyMove(\n","        self\n","    ):\n","        raise NotImplementedError()\n","\n","    def IsTerminal(\n","        self\n","    ):\n","        '''\n","        Check if a terminal node is reached (10 turns have passed and this is the last turn).\n","        '''\n","        raise NotImplementedError()\n","\n","    def GetScores(\n","        self\n","    ):\n","        raise NotImplementedError()\n","\n","    def LastPlayer(\n","        self\n","    ):\n","        '''\n","        This methods know the last player to move.\n","        '''\n","        raise NotImplementedError()\n","\n","    def CloneState(\n","        self\n","    ):\n","        '''\n","        This method clones the current IGameState.\n","        '''\n","        raise NotImplementedError()\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":74,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"_he7gC-AYY2R"},"outputs":[],"source":["class IGameMove(object):\n","    '''\n","    This interface class represents a MOVE in the game.\n","\n","    It should contain the definition of legal moves\n","    and routines to evaluate them.\n","\n","    It should be able to be passed as an argument to the IGameState and update its general state.\n","\n","    It should be the output of the ITreeNode object that performs a tree search among the possible moves and chooses the optimal one.\n","    '''\n","\n","    def __init__(self) -> None:\n","        pass\n","\n","    def GetMoves(self) -> None:\n","        '''Simulate another player's strategy and returns a move.'''\n","        raise NotImplementedError()\n","\n","    def EvalMoves(\n","        self\n","    ):\n","        '''Checks if two moves are equal.'''\n","        raise NotImplementedError()"]},{"cell_type":"markdown","metadata":{"id":"qE1TDb0AYQ-E"},"source":["A final note: these are __generic__ classes. The actual implementation for a _Scopone_ game will be built by exploiting _inheritance_, allowing us to keep track of all the requirements but to instantiate and code all we need to build a working _Scopone_-playing AI."]},{"cell_type":"markdown","metadata":{"id":"DAZeJ5QCYY2T"},"source":["# Scopone classes\n","\n","As mentioned earlier, the Monte Carlo Tree Search algorithm (from now on, _MCTS_) needs to \"understand\" everything about the game and the scenario it finds itself in.\n","\n","The fundamental block of a game is a __card__ and, while using `tuple`s served us well so far, it is not enough to move forward: the first step, therefore, is to code a `Card` class that allows us to have both custom methods to invoke, a compact _container_ in which to store a complete description of the card, and to code a _custom behaviour_ by using __operator overloading__ and other __magic methods__.\n"]},{"cell_type":"markdown","metadata":{"id":"d4q4NaZ_H797"},"source":["\n","## `Card`"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":74,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"F2Ver9hWH797"},"outputs":[],"source":["class Card(object):\n","    \"\"\"\n","    This object represent a card, which is defined by:\n","\n","    - Rank: the number corresponding to the card.\n","    - Suit (Seme): the suit to which it belongs.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        Rank: int = NA,\n","        Suit: int = NA\n","        ) -> None:\n","        \"\"\"\n","        To instantiate a Card object, a Rank and Suit have to be specified.\n","        It is possible to instantiate an \"empty\" card, in which both Rank and Suits NA.\n","\n","        Args:\n","            Rank (int, optional): Defaults to NA.\n","            Suit (int, optional): Defaults to NA.\n","        \"\"\"\n","        self.Rank = Rank\n","        self.Suit = Suit\n","\n","    def __str__(self) -> str:\n","        \"\"\"\n","        This method allows to obtain a custom representation of a Card object when passed as an argument to print.\n","        \"\"\"\n","        Suits = {\n","            1: \"Ori\",\n","            2: \"Coppe\",\n","            3: \"Spade\",\n","            4: \"Bastoni\"\n","        }\n","        return f\"{self.Rank} of {Suits[self.Suit]}, valued {self.Value()} rewards.\"\n","\n","    def __repr__(self) -> str:\n","        \"\"\"\n","        This method is used to obtain a compact representation of a Card object.\n","        \"\"\"\n","        return f\"Card: ({self.Rank}, {self.Suit})\"\n","\n","    def __hash__(self) -> int:\n","        \"\"\"\n","        Card objects need to be hashable.\n","        \"\"\"\n","        return 666\n","\n","    def __iter__(self) -> list:\n","        \"\"\"\n","        Card objects are iterable, only once, returning theirself.\n","        \"\"\"\n","        self.n = 0\n","        return self\n","\n","    def __next__(self) -> None:\n","        \"\"\"\n","        Card objects are iterable, only once, returning theirself.\n","        \"\"\"\n","        if self.n < 1:\n","            self.n += 1\n","            return self\n","        else:\n","            raise StopIteration\n","\n","    def __len__(self) -> int:\n","        \"\"\"\n","        Card objects have length 1.\n","        \"\"\"\n","        return 1\n","\n","    def Rank(self) -> int:\n","        return self.Rank\n","\n","    def Suit(self) -> int:\n","        return self.Suit\n","\n","    def Value(self) -> int:\n","        \"\"\"\n","        This method is used to store and retrieve the reward associated with a Card.\n","        \"\"\"\n","        values = {(1, 1): 26, (2, 1): 22, (3, 1): 23, (4, 1): 24, (5, 1): 25, (6, 1): 28, (7, 1): 139, (8, 1): 20, (9, 1): 20, (10, 1): 139,\n","          (1, 2): 16, (2, 2): 12, (3, 2): 13, (4, 2): 14, (5, 2): 15, (6, 2): 18, (7, 2): 29, (8, 2): 10, (9, 2): 10, (10, 2): 10,\n","          (1, 3): 16, (2, 3): 12, (3, 3): 13, (4, 3): 14, (5, 3): 15, (6, 3): 18, (7, 3): 29, (8, 3): 10, (9, 3): 10, (10, 3): 10,\n","          (1, 4): 16, (2, 4): 12, (3, 4): 13, (4, 4): 14, (5, 4): 15, (6, 4): 18, (7, 4): 29, (8, 4): 10, (9, 4): 10, (10, 4): 10}\n","        return values[self.Rank, self.Suit]\n","\n","    def __add__(self, other) -> int:\n","        if isinstance(other, Card):\n","            return self.Rank + other.Rank\n","        raise TypeError(\n","            (f\"unsupported operand type(s) for +: \"\n","             f\"{type(self)} and {type(other)}\"))\n","\n","    def __radd__(self, other) -> int:\n","        if other == 0:\n","            return self\n","        return self.__add__(other)\n","\n","    def __mul__(self, other) -> int:\n","        if isinstance(other, Card):\n","            return self.Value() + other.Value()\n","        raise TypeError(\n","            (f\"unsupported operand type(s) for *: \"\n","             f\"{type(self)} and {type(other)}\"))\n","\n","    def __eq__(self, other) -> bool:\n","        if isinstance(self, Card) and isinstance(other, Card):\n","            if self.Rank == other.Rank and self.Suit == other.Suit:\n","                return True\n","            else:\n","                return False\n","        elif isinstance(self, tuple) and isinstance(other, Card):\n","            rank, suit = other.Rank, other.Suit\n","            if self[0] == rank and self[1] == suit:\n","                return True\n","            else:\n","                return False\n","        elif isinstance(self, Card) and isinstance(other, tuple):\n","            rank, suit = self.Rank, self.Suit\n","            if other[0] == rank and other[1] == suit:\n","                return True\n","            else:\n","                return False\n"]},{"cell_type":"markdown","metadata":{"id":"g1i3WxehH798"},"source":["Now, a brief description of how a `Card` works, with some examples.\n","\n","---\n","\n","A `Card` object can be instantiated without assigning any attribute:"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"Bupg3lyNH798","outputId":"e696b287-3995-4291-f52b-4ea93e72e959"},"outputs":[{"name":"stdout","output_type":"stream","text":["Rank <NA>\n","Suit <NA>\n"]}],"source":["my_card = Card()\n","print_attributes(my_card)"]},{"cell_type":"markdown","metadata":{"id":"EAsXpKlIH798"},"source":["`print` works in a specific way when associated with a `Card`:"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"GFHh1VThH798","outputId":"d26b9c74-02c4-4785-f5ca-bc6ea04e83b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["7 of Coppe, valued 29 rewards.\n"]}],"source":["\n","my_card.Rank, my_card.Suit = (7, 2)\n","\n","print(my_card)\n"]},{"cell_type":"markdown","metadata":{"id":"lWTfWrh-H799"},"source":["To extract the _game-point_ (__reward__) value for a card, invoke the `Value()` method:"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"liAAvCAyH799","outputId":"3f2de97a-286d-49ff-ffee-9a81a04e6c47"},"outputs":[{"data":{"text/plain":["29"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["my_card.Value()"]},{"cell_type":"markdown","metadata":{"id":"R1KbzFbPH799"},"source":["To sum the __ranks__ of two cards, you can use `+`:"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"PQb90ljGH79-","outputId":"f6640d6d-bb61-4010-a14c-325a1d16cee9"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["card1 = Card(2, 1)\n","card2 = Card(2, 3)\n","\n","card1 + card2"]},{"cell_type":"markdown","metadata":{"id":"SKaxIkFyH79-"},"source":["To sum their __rewards__ values, use `*`.\n","\n","E.g.: (2, 1) and (2, 3) are valued both 12 _rewards_:"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"fHQoJyfjH79-","outputId":"db430259-2b65-459d-ea05-66b651edcf7a"},"outputs":[{"data":{"text/plain":["34"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["card1*card2"]},{"cell_type":"markdown","metadata":{"id":"8l_CmjawH79-"},"source":["To check whether two cards are equal, you can use the __boolean__ operator `==`:"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"QhS9HItcH79-","outputId":"60f51585-4d6f-442c-d6bc-79741bb354bc"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["card3 = Card(2, 1)\n","\n","card1 == card3"]},{"cell_type":"markdown","metadata":{"id":"C6ZGEaT9YQ-J"},"source":["This works also if we want to compare the `Card` representation with a `tuple` representation of the same card; this is required to allow the MCTS to work with `Greedy` or `Intermediate` based players."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"sL0VQN3_YQ-J","outputId":"d471804b-38ec-43c8-d993-205f9b78b5df"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["Card(2,1) == (2,1)"]},{"cell_type":"markdown","metadata":{"id":"OVQVkUENUJoD"},"source":["Note that a `Card` object can be _iterated_, but only once:"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"HIv9EEDOUJoD","outputId":"88297b84-ff3b-4922-8922-26f7885d241c"},"outputs":[{"name":"stdout","output_type":"stream","text":["2 of Ori, valued 22 rewards.\n"]}],"source":["for iterables in card1:\n","    print(iterables)"]},{"cell_type":"markdown","metadata":{"id":"r5PEdFeLH79_"},"source":["To conclude, we coded other _helper functions_ based on the `Card` objects that allow us to translate between _tuples_ and `Card`s effortlessly.\n","\n","To convert a `tuple` into a `Card` object:"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"9-x51OHpH79_"},"outputs":[],"source":["def convert_to_card(\n","    card: tuple\n",") -> Card:\n","    \"\"\"\n","    This routine convert tuple object into Card object.\n","    If the object is already a Card, it returns its argument unmodified.\n","\n","    Args:\n","        card (tuple): a tuple describing a card, (rank, suit).\n","\n","    Returns:\n","        Card: a Card describing a card.\n","    \"\"\"\n","\n","    if not isinstance(card, Card):\n","\n","        new_card = Card()\n","        new_card.Rank, new_card.Suit = card\n","\n","        return new_card\n","\n","    elif isinstance(card, Card):\n","        return card"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"Dh9nEkurH79_","outputId":"e3b37b88-251a-420a-9206-7b015dc72940"},"outputs":[{"name":"stdout","output_type":"stream","text":["2 of Ori, valued 22 rewards.\n"]}],"source":["print(convert_to_card((2, 1)))"]},{"cell_type":"markdown","metadata":{"id":"LI0fSfjpUJoE"},"source":["To convert a `Card` into a `tuple`:"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1693230348635,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"lLfBPHr-H79_"},"outputs":[],"source":["def convert_to_tuple(\n","    card: Card\n","    ) -> tuple:\n","\n","    temp = card.Rank, card.Suit\n","    return temp"]},{"cell_type":"markdown","metadata":{"id":"iD_0jhgVH7-A"},"source":["Other useful functions that require the definition of `Card` objects to work involve:\n","\n","- A routine to sum `Card`s `Rank`s in some specific scenarios.\n","- A routine to `unpack_moves`."]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1693230348636,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"NUJS8cX2H7-A"},"outputs":[],"source":["def sum_combination_ranks(\n","    CardCombination: list\n","    ):\n","    \"\"\"\n","    Given a combination of cards, returns the sum of their ranks.\n","    To be used to compare the Rank of a move (Card from a player's Hand) and the total Rank represented by the combination,\n","    to understand possible picks and compare.\n","\n","    Args:\n","        CardCombination (list): a list of Card objects.\n","\n","    Returns:\n","        int: sum of each Card object rank.\n","    \"\"\"\n","\n","    combination_sum = sum(card.Rank for card in CardCombination)\n","\n","    return combination_sum\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1693230348636,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"U3Du_D44UJoE"},"outputs":[],"source":["def unpack_moves(MovesDict: dict) -> dict:\n","    \"\"\"\n","    This unpack a moves dictionary by yielding a simpler data structure.\n","    Args:\n","        MovesDict (dict): a dictionary of moves\n","\n","            key: card to be played.\n","            values: card or combination of cards to be taken from the table.\n","\n","    Yields:\n","        dict: a sequence of dictionaries each representing a single move.\n","    \"\"\"\n","\n","    for key in MovesDict.keys():\n","        if len(MovesDict[key]) == 0:\n","                yield {key: list()}\n","        else:\n","            for move in MovesDict[key]:\n","                if isinstance(move, Card):\n","                    yield {key: move}\n","\n","                elif isinstance(move, list):\n","                    if key.Rank == sum_combination_ranks(move) or len(move) == 0:\n","                        yield {key: move}"]},{"cell_type":"markdown","metadata":{"id":"1avV9qo9YQ-N"},"source":["To represent and __update__ a game state, it is not enough to return a `move`: while simulating the game, the MCTS needs also to modify the `Table`, by adding discarded cards or removing picks. This `unpack_moves` method uses `yield` to create an __iterator__ object that contains a sequence of _dictionaries_. Each of these dictionaries is structured in this way:\n","\n","- `key`: the `Card` to be played.\n","- `values`: the `Card` or a list representing a combination of cards to be picked. An empty list represent a situation in which no picks can be made, therefore the player has to discard a card from his hand."]},{"cell_type":"markdown","metadata":{"id":"8OxNFbVB7L1Y"},"source":["## `ScoponeMove`\n","\n","`ScoponeMove` inherits from `IGameMove` and its main duty is to simulate the other players' choices, while also containing _utilities_ to evaluate moves and get possible combinations.\n","\n","To simulate the other players' strategy, we needed a model of their behaviour. To do so, this class effectively works as a _wrapper_ for the `Greedy` and `Intermediate` functions, which are chosen to model the response to the MCTS player possible choices.\n","\n","### Code"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1693230348636,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"YMheK3XqYY2V"},"outputs":[],"source":["class ScoponeMove(IGameMove):\n","    '''\n","    This class inherits from IGameMove and, given the rules of Scopone and the definition of the current IGameState,\n","    either apply a strategy to select which card to play or evaluates whether two cards yield the same points.\n","    '''\n","\n","    def __init__(\n","        self,\n","        LegalMoves: list = [],\n","        Table: list = [],\n","        Deck: list = [],\n","        values: dict = Greedy_MOD.values,\n","        ) -> None:\n","        \"\"\"\n","        This section assigns all arguments needed to define the current state of the game.\n","\n","        Args:\n","            values (dict, optional): a dictionary that contains the points associated with each card. Defaults to Greedy_MOD.values.\n","            LegalMoves (list, optional): A list of tuples containing the player's hand. Defaults to [].\n","            Table (list, optional): A list of tuples containing all the cards on the table. Defaults to [].\n","            Deck (list, optional): A list of tuples containing all the cards on the deck. Defaults to [].\n","        \"\"\"\n","\n","        super().__init__()\n","\n","        self.Hand = LegalMoves\n","        self.Table = Table\n","        self.Deck = Deck\n","        self.values = values\n","\n","    def GetMove(\n","        self,\n","        Greedy: bool = True,\n","        Standalone:bool = False\n","        ) -> tuple:\n","        \"\"\"\n","        This method, given the elements of the game (LegalMoves, Table, Deck), outputs a tuple representing the card chosen by applying the Intermediate or Greedy (default) strategies.\n","\n","        Args:\n","            game_mode (bool, optional): Decide whether to use the Greedy strategy or not. Defaults to False.\n","\n","        Returns:\n","            tuple: a card, representing the move chosen by the AI.\n","\n","        Yields:\n","            Iterator[tuple]: a card, as defined by points and rank.\n","        \"\"\"\n","\n","        if Greedy:\n","            return Greedy_MOD.Greedy(\n","                legalMoves = self.Hand,\n","                table = self.Table,\n","                Standalone=Standalone,\n","                values = values\n","                )\n","\n","        else:\n","            return Intermediate.Intermediate(\n","                legalMoves = self.Hand,\n","                table = self.Table,\n","                deck = self.Deck,\n","                Standalone=Standalone,\n","                values = values\n","                )\n","\n","    def GetCombinations(\n","        Table: list\n","        ) -> dict:\n","        \"\"\"\n","        This method returns all possible combinations of table cards\n","\n","        Args:\n","            Table (tuple): a list of tuples representing cards.\n","\n","        Returns:\n","            Combinations: a dictionary of summed ranks as keys and combinations of cards as values representing the legal combined picks.\n","        \"\"\"\n","\n","        available_combinations = []\n","\n","        for L in range(2, len(Table) + 1):\n","            available_combinations.append(itertools.combinations(map(convert_to_card, Table), L))\n","\n","        Combinations = {key: list() for key in range(1, 11)}\n","\n","        for combinations in available_combinations:\n","            for combination in combinations:\n","                combination_sum = 0\n","                combination_cards = []\n","                for card in combination:\n","                    combination_sum += card.Rank\n","                    combination_cards.append(card)\n","                if combination_sum < 11:\n","                    Combinations[combination_sum].append(combination_cards)\n","\n","\n","        return Combinations\n","\n","    def EvalMoves(\n","        move1: dict,\n","        move2: dict\n","        ) -> tuple:\n","        \"\"\"\n","        This method takes two moves as arguments, in the form:\n","\n","        move = {card to be played: card or list of cards (combination) to be picked from the table}\n","\n","        Returns a tuple (bool, dict) with:\n","            - bool: truth value resulting from the comparison of the total reward corresponding to that move.\n","            - dict: the best move among the two inputs.\n","\n","        Args:\n","            move1 (dict): a dict object representing a move.\n","            move2 (dict): a dict object representing a move.\n","\n","        Returns:\n","            tuple(bool, dict):\n","            - bool: truth value resulting from the comparison of the total reward corresponding to that move.\n","            - dict: the best move among the two inputs.\n","        \"\"\"\n","\n","        move1_cards_list = list()\n","        move1_tot_reward = 0\n","\n","        for move, combinations in move1.items():\n","            move1_cards_list.append(convert_to_card(move))\n","            if isinstance(combinations, list):\n","                for pick in combinations:\n","                    move1_cards_list.append(convert_to_card(pick))\n","            if isinstance(combinations, tuple):\n","                move1_cards_list.append(convert_to_card(combinations))\n","\n","\n","        move1_tot_reward = sum(card.Value() for card in move1_cards_list)\n","\n","        move2_cards_list = list()\n","        move2_tot_reward = 0\n","\n","        for move, combinations in move2.items():\n","            move2_cards_list.append(convert_to_card(move))\n","            if isinstance(combinations, list):\n","                for pick in combinations:\n","                    move2_cards_list.append(convert_to_card(pick))\n","            if isinstance(combinations, tuple):\n","                move2_cards_list.append(convert_to_card(combinations))\n","\n","        move2_tot_reward = sum(card.Value() for card in move2_cards_list)\n","\n","        if move1_tot_reward > move2_tot_reward:\n","            BestMove = move1\n","        elif move1_tot_reward < move2_tot_reward:\n","            BestMove = move2\n","        else:\n","            # If two cards yield the same value, flip a coin to decide which one to play.\n","            diceroll = random.randint(0, 1000)\n","            if diceroll < 500:\n","                BestMove = move1\n","            else:\n","                BestMove = move2\n","\n","        return move1_tot_reward == move2_tot_reward, BestMove"]},{"cell_type":"markdown","metadata":{"id":"g8_k4k8q7L1Z"},"source":["---\n","### Test"]},{"cell_type":"markdown","metadata":{"id":"zUF-P09x7L1Z"},"source":["#### `GetMove`"]},{"cell_type":"markdown","metadata":{"id":"JCcqQjlBUJoF"},"source":["\n","##### `Intermediate`:"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1693230348636,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"yI_n1bmi7L1Z","outputId":"ee8cce19-4a10-45f4-eec0-e801d7f2d819"},"outputs":[{"data":{"text/plain":["{(5, 3): [(1, 1), (4, 2)]}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["ScoponeMove(\n","    LegalMoves=test1_PlayersCards[0],\n","    Table= test1_Table\n","    ).GetMove(\n","        Greedy=False,\n","        Standalone=False\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9269,"status":"ok","timestamp":1693230357896,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"fmYa-6_vYQ-P","outputId":"29f344cf-1230-42a6-9921-21faeafe032f"},"outputs":[{"name":"stdout","output_type":"stream","text":["34.7 µs ± 768 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"]}],"source":["%timeit ScoponeMove(LegalMoves=test1_PlayersCards[0], Table=test1_Table ).GetMove(Greedy=False, Standalone=False)"]},{"cell_type":"markdown","metadata":{"id":"ac5lQX5L7L1Z"},"source":["##### `Greedy`:\n","\n","The following code cell tests the `Greedy` inside the `GetMove` wrapper method."]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1693230357896,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"VI2ve1Rw7L1Z","outputId":"a9ff92b0-10ed-487d-c9c7-8414be66742a"},"outputs":[{"data":{"text/plain":["{(5, 3): [(1, 1), (4, 2)]}"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["ScoponeMove(\n","    LegalMoves=test1_PlayersCards[0],\n","    Table= test1_Table\n","    ).GetMove(\n","        Greedy=True,\n","        Standalone=False\n",")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3277,"status":"ok","timestamp":1693230361168,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"UIk8hI0CYQ-P","outputId":"92cb46b4-2766-4579-e129-596c485c17b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["16.8 µs ± 142 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"]}],"source":["%timeit ScoponeMove(LegalMoves=test1_PlayersCards[0], Table=test1_Table ).GetMove(Greedy=True, Standalone=False)"]},{"cell_type":"markdown","metadata":{"id":"z533kZNDYQ-Q"},"source":["> __Spoiler__: this is _not_ the best move, given the whole game tree.\n","\n","As we will see later on, the MCTS consistently plays a different strategy than either the `Intermediate` and `Greedy` AIs, in this case, taking the 6 and 4 in the table with the 10 in its hand: even though it rewards less point immediatly, it will lead to worse outcomes by the end of the game."]},{"cell_type":"markdown","metadata":{"id":"1XQ6UBNL7L1a"},"source":["#### `GetCombinations`\n","\n","When facing a complex game scenario, such as `test_1`, in which with a single card you can pick alternative singles or combinations from the table.\n","\n","To test the `GetCombinations` method, we modified the table by adding a single picks. In other words, if the player has a (10, 3), this method consider all the alternatives and outputs a dictionary in which the key represent a `Rank` and each value is updated if a corresponding combination add up to the played card `Rank`."]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":69,"status":"ok","timestamp":1693230361168,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"g0e1HXRK7L1a"},"outputs":[],"source":["Table=[(1, 1), (4, 2), (9, 4), (10, 2), (6, 3)]"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64,"status":"ok","timestamp":1693230361168,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"Hk5nIzcA7L1b","outputId":"eef2463c-2bbb-4960-9293-d5cda38df5b8"},"outputs":[{"data":{"text/plain":["{1: [],\n"," 2: [],\n"," 3: [],\n"," 4: [],\n"," 5: [[Card: (1, 1), Card: (4, 2)]],\n"," 6: [],\n"," 7: [[Card: (1, 1), Card: (6, 3)]],\n"," 8: [],\n"," 9: [],\n"," 10: [[Card: (1, 1), Card: (9, 4)], [Card: (4, 2), Card: (6, 3)]]}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["ScoponeMove.GetCombinations(Table)"]},{"cell_type":"markdown","metadata":{"id":"LhlFSWSYUJoF"},"source":["#### `EvalMoves`"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":64,"status":"ok","timestamp":1693230361168,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"9tCS2k1zUJoF"},"outputs":[],"source":["move1 = {\n","    (10, 1): [\n","        (6, 3),\n","        (3, 4)\n","        ]\n","    }\n","move2 = {\n","    (10, 2):\n","        (10, 1)\n","    }\n","move3 = {\n","    (10, 1): [\n","        (6, 2),\n","        (3, 4)\n","        ]\n","    }\n","move4 = {\n","    (10, 1): [\n","        (7, 1),\n","        (3, 1)\n","        ]\n","    }"]},{"cell_type":"markdown","metadata":{"id":"4tQzTBc_UJoG"},"source":["`move1` and `move3` yield equal rewards; the worst move is `move2`, the best `move4`.\n","\n","> Note that this is not an actual game scenario made of legal moves, but just test."]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1693230361168,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"Te2WzsqRUJoG","outputId":"5eda452f-60bf-4b72-9478-79a3c4968d37"},"outputs":[{"data":{"text/plain":["(True, {(10, 1): [(6, 3), (3, 4)]})"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["\n","ScoponeMove.EvalMoves(\n","    move1,\n","    move3\n",")"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1693230361168,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"mFJ8l4gvUJoG","outputId":"9e6a8af9-d54f-4c79-e7d2-4632d2695cf4"},"outputs":[{"data":{"text/plain":["(False, {(10, 1): [(6, 3), (3, 4)]})"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["ScoponeMove.EvalMoves(\n","    move1,\n","    move2\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1693230361168,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"ue1yAJyAUJoG","outputId":"cb82f6f7-73c9-45d5-d2d3-b3d2be7c191f"},"outputs":[{"data":{"text/plain":["(False, {(10, 1): [(7, 1), (3, 1)]})"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["ScoponeMove.EvalMoves(\n","    move1,\n","    move4\n",")"]},{"cell_type":"markdown","metadata":{"id":"7_ihxQdK7L1b"},"source":["## `ScoponeGameState`\n","\n","This class inherits from `IGameState` and develops it extensively. The main reason is that we made a fundamental design choice: the `ScoponeGameState` not only works as a wrapper for everything that the MCTS would need to explore the game tree and simulate other players' strategy, updating the game as it goes on searching for the best move, but it also represents (conceptually) a __node__ in the game tree.\n","\n","In other words, we decided that since a __game state__ can be thought and modelled as a specific point in the game, it also can work as the coded representation of a __node__.\n","\n","This choice makes for a complex object, full of different methods and with a lengthy list of attributes: everything it needs to define a scenario, apply the best move (modifying both its hand and the table and updating the scores), check if the game is in its last turn, find the children of a node (game state), store the information about the node's parents, and so on. Moreover, we made `ScoponeGameStates` _hashable_, as it is a requirement for tree nodes."]},{"cell_type":"markdown","metadata":{"id":"CVJ7-78f7L1b"},"source":["### Code"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"zB0zqz-S7L1b"},"outputs":[],"source":["class ScoponeGameState(IGameState):\n","    \"\"\"\n","    This object completely defines the current game 'state' situation.\n","\n","    It contains methods to:\n","\n","    - get the available moves,\n","    - apply a move,\n","    - check if it is a terminal state,\n","    - get the scores fo the game,\n","    - know the last player to move,\n","    - clone the state.\n","    - compute the rewards.\n","    - find all the children of the current ScoponeGameState.\n","    - find a random children of the current ScoponeGameState.\n","    \"\"\"\n","    # def __new__(cls, *args, **kwargs):\n","    #     print(\"####### I have created a new ScoponeGameState.\")\n","    #     return super().__new__(cls)\n","\n","    def __init__(\n","        self,\n","        PlayerPosition: int,\n","        PlayersCards: dict,\n","        Team: str,\n","        TeamScores: dict,\n","        Table: list = [],\n","        Deck: list = [],\n","        LastTaker: int = NA,\n","        ParentMove: dict = NA,\n","        values: dict = Greedy_MOD.values\n","        ) -> None:\n","        \"\"\"\n","        This section assigns all arguments needed to define the current state of the game, for all players.\n","\n","        Args:\n","            PlayerPosition (int): the position of the current player. Might be a number from 0 to 3, based on the starting turn.\n","            PlayersCards (dict): a dictionary containing a list of tuples representing each player's hand.\n","            Team(str): a string representing the current player's team.\n","            TeamScores (dict): a dictionary representing team A (player 0, 2) and team B (player 1, 3) scores.\n","            Table (list, optional): a list of tuples containing all the cards on the table. Defaults to [].\n","            Deck (list, optional): a list of tuples containing all the cards on the deck Defaults to [].\n","            LastTaker(int, optional): an integer indicator that stores the position of the last player that has picked cards from the table.\n","            ParentMove(dict, optional): a dictionary representing the MCTS move that originated the current GameState.\n","            values (dict, optional): points associated to each card. Defaults to Greedy_MOD.values.\n","        \"\"\"\n","\n","        self.PlayerPosition = PlayerPosition\n","        self.PlayersCards = PlayersCards\n","        self.Team = Team\n","        self.Hand = PlayersCards[PlayerPosition]\n","        self.TeamScores = TeamScores\n","        self.Reward = self.ComputeRewards()\n","        self.Table = Table\n","        self.Deck = Deck\n","        self.LastTaker = LastTaker\n","        self.ParentMove = ParentMove\n","        self.values = values\n","\n","    def __eq__(self, other) -> bool:\n","        check = [self.PlayerPosition == other.PlayerPosition,\n","                self.PlayersCards == other.PlayersCards,\n","                self.Team == other.Team,\n","                self.Hand == other.Hand,\n","                self.TeamScores == other.TeamScores,\n","                self.Table == other.Table,\n","                self.Deck == other.Deck,\n","                self.values == other.values\n","        ]\n","\n","        if all(check) == True:\n","            return True\n","        else:\n","            return False\n","\n","    def __hash__(self) -> int:\n","        return super().__hash__()\n","\n","    def __repr__(self) -> str:\n","        if isinstance(self.ParentMove, Card):\n","            return f\"###\\nScoponeGameState:\\n###\\n>Parent Move: {self.ParentMove}.\\n> Current hand: {self.Hand}\\n> Current table: {self.Table}\\n> Points: {self.TeamScores}\\nThe reward for this State is: {self.Reward}.\\n###\"\n","        elif isinstance(self.ParentMove, ScoponeGameState):\n","            state = self.ParentMove\n","            return f\"###\\nScoponeGameState:\\n###\\n>Parent State: {state.ParentMove}.\\n> Current hand: {state.Hand}\\n> Current table: {state.Table}\\n> Points: {state.TeamScores}\\nThe reward for this State is: {state.Reward}.\\n###\"\n","        else:\n","            return f\"###\\nScoponeGameState:\\n###\\n>Parent Move: {self.ParentMove}.\\n> Current hand: {self.Hand}\\n> Current table: {self.Table}\\n> Points: {self.TeamScores}\\nThe reward for this State is: {self.Reward}.\\n###\"\n","\n","    def CloneState(self) -> IGameState:\n","        \"\"\"\n","        This method creates a copy of the current game state and all its attributes.\n","\n","        Returns:\n","            ScoponeGameState: a deepcopy of the current ScoponeGameState.\n","        \"\"\"\n","\n","        return copy.deepcopy(self)\n","\n","    def IsTerminal(self) -> bool:\n","        \"\"\"\n","        This is method to check whether the GameState corresponds to the last turn.\n","\n","        Returns:\n","            bool: True if it is the last turn, otherwise False.\n","        \"\"\"\n","\n","        if len(self.Hand) == 0:\n","            return True\n","        else:\n","            return False\n","\n","    def GetScores(self) -> tuple:\n","        \"\"\"\n","        This EVEN BETTER method gets all the available scores to be rewarded to the player at the current game state.\n","        Given a table and the player's hand, it will return a list of scores, a dictionary of single picks moves, and a dictionary of combinations.\n","\n","        Returns:\n","            A TUPLE with:\n","\n","            Scores: A list of all the scores available for the taking.\n","            SinglePicks: A dictionary of all the single-pick moves that can be made and the correspondent points.\n","                - The dictionary key correspond to the rank, while the value is the card.\n","            TableCombinations: A list of all the combinations of cards that can be taken and their correspondent point.\n","                - The dictionary key correspond to the sum of the ranks of all the card in the combinations, while the values are the cards in that particular combination.\n","        \"\"\"\n","\n","        SinglePicks = {card.Rank: card for card in map(convert_to_card, self.Table)}\n","\n","        TableCombinations = ScoponeMove.GetCombinations(self.Table)\n","\n","        Scores = []\n","\n","        for card in SinglePicks.values():\n","            Scores.append(card.Value())\n","\n","        for combinations_list in TableCombinations.values():\n","            total_score = 0\n","            for combination in combinations_list:\n","                for card in combination:\n","                    total_score *= card.Value()\n","                Scores.append(total_score)\n","\n","        return Scores, SinglePicks, TableCombinations\n","\n","    def ComputeRewards(self) -> int:\n","        \"\"\"\n","        This method takes the two teams' scores and computes their difference.\n","\n","        Points scored for the player's team are positive integers, while the other's team are negative: this\n","        is used to teach the algorithm the correct behaviour in a reinforcement learning setting.\n","\n","        Returns:\n","            int: the difference between the player's and the other's teams scores.\n","        \"\"\"\n","\n","        if self.Team == \"Hand\":\n","            StateReward = self.TeamScores[\"Hand\"] - self.TeamScores[\"Deck\"]\n","        elif self.Team == \"Deck\":\n","            StateReward = self.TeamScores[\"Deck\"] - self.TeamScores[\"Hand\"]\n","\n","        return StateReward\n","\n","\n","    def GetAvailableMoves(self) -> list[dict]:\n","        \"\"\"\n","        This method indicates all the available cards to be played by the current player.\n","\n","        Moves are represented by the card played to make that move.\n","        Given a game state, it will return all the available moves, single picks and combinations.\n","\n","        Returns:\n","            list: list of CARDS that can be played at that particular turn.\n","\n","        IMPORTANT: if a card is present more than once, it might pick either a single card or a combination.\n","        \"\"\"\n","\n","\n","        AvailableMoves = {card: card for card in map(convert_to_card, self.Hand)}\n","\n","\n","        _, SinglePicks, TableCombinations = self.GetScores()\n","\n","\n","        LegalMoves = {move: list() for move in AvailableMoves.values()}\n","\n","        for move in AvailableMoves.values():\n","            for pick in SinglePicks.values():\n","                if move.Rank == pick.Rank:\n","                    LegalMoves[move].append(pick)\n","\n","        for combinations in TableCombinations.values():\n","            for combination in combinations:\n","                for move in LegalMoves.keys():\n","                    if move.Rank == sum_combination_ranks(combination):\n","                        LegalMoves[move].append(combination)\n","\n","        return LegalMoves\n","\n","    def ApplyMove(\n","            self,\n","            BestMove: dict\n","            ):\n","        \"\"\"\n","        Given a move in the following format:\n","\n","        {card to be played: card or combination of cards to be taken}\n","\n","        returns a modified GameState object that applies it to the current GameState.\n","        This implies:\n","\n","        - Removing the card from the player's hand.\n","        - Removing the picked card/s from the table.\n","        - Adding the resulting reward to that team score.\n","\n","        Args:\n","            Move (dict): a dictionary in the form {card to be played: card or combination of cards to be taken}.\n","            The combination of cards is a list of tuples/Cards objects.\n","\n","            - Move key = card in your hand to be played. Also called move.\n","            - Move value = card/combinations of cards to be taken from the table. Also called pick.\n","                           A pick can either be a combination or a single card. Single cards are iterable once.\n","\n","        Returns:\n","            IGameState: a copy of the starting GameState modified by the effects of the BestMove.\n","        \"\"\"\n","\n","        # Reminder:\n","        #\n","        # BestMove key = card in your hand to be played.\n","        # BestMove value = card/combinations of cards to be taken from the table.\n","\n","        new_game_state = self.CloneState()\n","        new_table = list(map(convert_to_card, new_game_state.Table))\n","        new_hand = list(map(convert_to_card, new_game_state.Hand))\n","        new_score = 0\n","        updated_scores = new_game_state.TeamScores\n","\n","        picks_check = len(list(BestMove.values())[0])\n","\n","        if picks_check == 0 or len(new_game_state.Table) == 0:\n","            card_to_be_played = [card for card in map(convert_to_card, BestMove.keys())][0]\n","\n","            new_table.append(card_to_be_played)\n","            new_hand.remove(card_to_be_played)\n","\n","            new_game_state.Hand = list(map(convert_to_tuple, new_hand))\n","            new_game_state.PlayersCards[new_game_state.PlayerPosition] = new_game_state.Hand\n","            new_game_state.Table = list(map(convert_to_tuple, new_table))\n","\n","            return new_game_state\n","\n","        else:\n","            self.LastTaker = new_game_state.PlayerPosition\n","            for card_to_be_taken in BestMove.values():\n","                card_to_be_played = list(map(convert_to_card, [BestMove.keys()][0]))\n","\n","\n","                for card in new_hand:\n","                    # scorre tutte le carte in mano e toglie dalla lista la carta che vuole giocare\n","                    for move in card_to_be_played:\n","                        if move == card:\n","                            new_hand.remove(card)\n","                            new_score += card.Value()\n","\n","\n","\n","                    for card in card_to_be_taken:\n","                        #scorre tutte le carte in tavola e toglie dalla lista tavolo la carta/combinazione di carte\n","                        if isinstance(card_to_be_taken, tuple):\n","                            card_to_be_taken = convert_to_card(card_to_be_taken)\n","                        if isinstance(card, int):\n","                            card = card_to_be_taken\n","                        for pick in new_table:\n","                            if isinstance(pick, list):\n","                                for card_to_remove in pick:\n","                                    if card_to_remove == card:\n","                                        new_table.remove(pick)\n","                                        new_score += pick.Value()\n","                            elif isinstance(pick, Card) and pick == card:\n","                                new_table.remove(pick)\n","                                new_score += pick.Value()\n","                            elif isinstance(pick, tuple) and pick == card:\n","                                pick = convert_to_card(pick)\n","                                new_table.remove(pick)\n","                                new_score += pick.Value()\n","\n","            if len(new_table) == 0 and not self.IsTerminal():\n","                #aggiungi un punto perché hai fatto scopa\n","                new_score += 1000\n","\n","            new_players_cards = new_game_state.PlayersCards\n","            new_players_cards[new_game_state.PlayerPosition] = list(map(convert_to_tuple, new_hand))\n","\n","            updated_scores[new_game_state.Team] += new_score\n","\n","            new_game_state.PlayersCards = new_players_cards\n","            new_game_state.Hand = new_hand\n","            new_game_state.TeamScores = updated_scores\n","            new_game_state.Reward = new_game_state.ComputeRewards()\n","            new_game_state.Table = list(map(convert_to_tuple, new_table))\n","\n","            return new_game_state\n","\n","    def FindChildren(self) -> list:\n","        \"\"\"\n","        This methods applies all available moves and returns a list containing\n","        each of the corresponding modified GameStates.\n","\n","        IMPORTANT: this method is invoked to start a tree search as it considers all the possible\n","        moves.\n","\n","        Returns:\n","            list: a list of modified GameStates.\n","        \"\"\"\n","\n","        AvailableMoves = list(unpack_moves(self.GetAvailableMoves()))\n","\n","        Childrens = list()\n","\n","        for move in AvailableMoves:\n","            new_child = self.ApplyMove(move)\n","            new_child.ParentMove = move\n","            Childrens.append(new_child)\n","\n","        return Childrens\n","\n","    def FindRandomChildren(self) -> IGameState:\n","        \"\"\"\n","        To efficiently simulate a game, this method returns a random ScoponeGameState\n","        chosen from the available moves.\n","\n","        Returns:\n","            IGameState: a ScoponeGameState.\n","        \"\"\"\n","\n","        AllChildren = self.FindChildren()\n","\n","        RandomChild = AllChildren[random.randint(0, len(AllChildren) -1)]\n","\n","        return RandomChild\n"]},{"cell_type":"markdown","metadata":{"id":"F9jR_btlYY2V"},"source":["---\n","### Test\n","\n","To start our tests, we create our first `ScoponeGameState` representing the game defined as `test_1`:"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"9nSeNKFE7L1c"},"outputs":[],"source":["test1_SGS = ScoponeGameState(\n","    PlayerPosition=0,\n","    PlayersCards=test1_PlayersCards,\n","    Team=test1_Team,\n","    TeamScores=test1_TeamScores,\n","    Table=test1_Table\n",")"]},{"cell_type":"markdown","metadata":{"id":"QpnmTaSsYQ-T"},"source":["Note that creating a new game state prints a warning: this is used for debug purposes and to keep track of the algorithms computations.\n","\n","To analyse a `ScoponeGameState`, you can either use `print_attributes`, which allows you to have a comprehensive view:"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"CqJEU2Tb7L1c","outputId":"aa23e29b-54d0-48d4-eded-ca10805c75ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["PlayerPosition 0\n","PlayersCards {0: [(1, 2), (10, 4), (5, 3)], 1: [(2, 2), (9, 3), (8, 3)], 2: [(1, 3), (9, 2), (4, 3)], 3: [(10, 1), (10, 3), (3, 3)]}\n","Team Hand\n","Hand [(1, 2), (10, 4), (5, 3)]\n","TeamScores {'Hand': 500, 'Deck': 500}\n","Reward 0\n","Table [(1, 1), (4, 2), (9, 4), (6, 3)]\n","Deck []\n","LastTaker <NA>\n","ParentMove <NA>\n","values {(1, 1): 26, (2, 1): 22, (3, 1): 23, (4, 1): 24, (5, 1): 25, (6, 1): 28, (7, 1): 139, (8, 1): 20, (9, 1): 20, (10, 1): 139, (1, 2): 16, (2, 2): 12, (3, 2): 13, (4, 2): 14, (5, 2): 15, (6, 2): 18, (7, 2): 29, (8, 2): 10, (9, 2): 10, (10, 2): 10, (1, 3): 16, (2, 3): 12, (3, 3): 13, (4, 3): 14, (5, 3): 15, (6, 3): 18, (7, 3): 29, (8, 3): 10, (9, 3): 10, (10, 3): 10, (1, 4): 16, (2, 4): 12, (3, 4): 13, (4, 4): 14, (5, 4): 15, (6, 4): 18, (7, 4): 29, (8, 4): 10, (9, 4): 10, (10, 4): 10}\n"]}],"source":["print_attributes(test1_SGS)"]},{"cell_type":"markdown","metadata":{"id":"UVV2lUVMYQ-T"},"source":["However, this might result as _verbose_ in most situations: to obtain a more compact representation, call `print` on the `ScoponeGameState` object."]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"I5ivSFQQYQ-T","outputId":"d4680cfe-a7a8-4609-c82c-8cb1f87d21c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["###\n","ScoponeGameState:\n","###\n",">Parent Move: <NA>.\n","> Current hand: [(1, 2), (10, 4), (5, 3)]\n","> Current table: [(1, 1), (4, 2), (9, 4), (6, 3)]\n","> Points: {'Hand': 500, 'Deck': 500}\n","The reward for this State is: 0.\n","###\n"]}],"source":["print(test1_SGS)"]},{"cell_type":"markdown","metadata":{"id":"_S6NIy4LYQ-T"},"source":["This yields all the necessary information to evaluate the current situation."]},{"cell_type":"markdown","metadata":{"id":"46HTRigF7L1c"},"source":["#### `CloneState`"]},{"cell_type":"markdown","metadata":{"id":"iqQlEO57YQ-U"},"source":["This method is necessary to work in a \"_safe_\" way: while the computer makes all the computations necessary to evaluate or modify a `ScoponeGameState`, all the modifications need to be implemented on a _new_ instance, to avoid inadvertently modifying the original game state, which is used to perform a different _simulation_ or _rollout_.\n","\n","Once a `ScoponeGameState` has been created, invoking the methods create a separate copy that can be modified safely."]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"vuiT2uup7L1c"},"outputs":[],"source":["copy_gamestate_test = test1_SGS.CloneState()"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"IcE5KXln7L1c","outputId":"fe96bb4b-a2fd-403f-8daf-7659819036b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["PlayerPosition 0\n","PlayersCards {0: [(1, 2), (10, 4), (5, 3)], 1: [(2, 2), (9, 3), (8, 3)], 2: [(1, 3), (9, 2), (4, 3)], 3: [(10, 1), (10, 3), (3, 3)]}\n","Team Hand\n","Hand [(1, 2), (10, 4), (5, 3)]\n","TeamScores {'Hand': 500, 'Deck': 500}\n","Reward 0\n","Table [(1, 1), (4, 2), (9, 4), (6, 3)]\n","Deck []\n","LastTaker <NA>\n","ParentMove <NA>\n","values {(1, 1): 26, (2, 1): 22, (3, 1): 23, (4, 1): 24, (5, 1): 25, (6, 1): 28, (7, 1): 139, (8, 1): 20, (9, 1): 20, (10, 1): 139, (1, 2): 16, (2, 2): 12, (3, 2): 13, (4, 2): 14, (5, 2): 15, (6, 2): 18, (7, 2): 29, (8, 2): 10, (9, 2): 10, (10, 2): 10, (1, 3): 16, (2, 3): 12, (3, 3): 13, (4, 3): 14, (5, 3): 15, (6, 3): 18, (7, 3): 29, (8, 3): 10, (9, 3): 10, (10, 3): 10, (1, 4): 16, (2, 4): 12, (3, 4): 13, (4, 4): 14, (5, 4): 15, (6, 4): 18, (7, 4): 29, (8, 4): 10, (9, 4): 10, (10, 4): 10}\n"]}],"source":["print_attributes(copy_gamestate_test)"]},{"cell_type":"markdown","metadata":{"id":"IZO6rPEyUJoH"},"source":["#### `==` (comparison operator)\n","\n","This operator overloading, coded by the `__eq__` magic method, allows to use `==` to check whether two `ScoponeGameState` are equal."]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"0are9zVRUJoH","outputId":"9138caeb-7231-440a-ec46-ad7e987fa84b"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["copy_gamestate_test == test1_SGS"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1693230361169,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"LmA8oEFPQwhA","outputId":"e0489aad-88b8-4e95-aaed-3d20391f6b78"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["dummy_test1_SGS = ScoponeGameState(\n","    PlayerPosition=0,\n","    PlayersCards=test1_PlayersCards,\n","    Team=test1_Team,\n","    TeamScores=test1_TeamScores,\n","    Table=test1_Table\n",")\n","\n","dummy_test1_SGS == test1_SGS"]},{"cell_type":"markdown","metadata":{"id":"8gXcKqjaYQ-U"},"source":["This will be used extensively while exploring the tree: a __branch_ can be thought as a sequence of _nodes_ (game states); for two paths to be equal, each of these states must have the same parent and lead to the same children (in other words, all the `ScoponeGameState`s that make up the sequence will be equal).\n","\n","To avoid wasting computational resources, this method is used to check whether a path has been already explored fully and can therefore be skipped."]},{"cell_type":"markdown","metadata":{"id":"i932AI3VUJoI"},"source":["#### Are `ScoponeGameState`s hashable?\n","\n","Nodes in the game tree has to be hashable: the following code block checks whether the `__hash__` method works as expected."]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":599,"status":"ok","timestamp":1693230361760,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"_HKJzCjoUJoI","outputId":"92cfd24d-7a33-4704-9a2b-b20fd066efcb"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["isinstance(test1_SGS, typing.Hashable)"]},{"cell_type":"markdown","metadata":{"id":"XGQQgbeP7L1d"},"source":["#### `GetAvailableMoves`"]},{"cell_type":"markdown","metadata":{"id":"-BoY7OxRYQ-V"},"source":["This method is used to create a list of all the available _legal_ moves for the AI player. It is implemented by putting together several already coded methods and utility functions, such as `GetScores` and `convert_to_card`.\n","\n","As we have seen earlier, the MCTS needs to have a computational _description_ of a Scopone game; however, not necessarily it is interfaced with a human player of another MCTS agent: this means that this method (as `ApplyMove`) needs to be able to operate either with `Card`s, `tuple`s, or both.\n","\n","Metaphorically, it is the first method in which we see that the class implementation of the algorithm is used to create a way for the program to _understand_ the game to analyse it and make a move by creating a custom _environment_, which at the same time is able to interface with a game setting and rule-based AIs in which the implementation is simpler and do not need a fully constructed information about the game and its rule to play.\n","\n","First of all, the algorithm computes __all the possibilities__: single picks, combinations, and their relative scores, operating on an instantiated node:"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1693230361760,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"olC9bJBxYQ-V","outputId":"6383f471-4b86-421d-9713-6c65b45e3982"},"outputs":[{"data":{"text/plain":["([26, 14, 10, 18, 0, 0, 0, 0],\n"," {1: Card: (1, 1), 4: Card: (4, 2), 9: Card: (9, 4), 6: Card: (6, 3)},\n"," {1: [],\n","  2: [],\n","  3: [],\n","  4: [],\n","  5: [[Card: (1, 1), Card: (4, 2)]],\n","  6: [],\n","  7: [[Card: (1, 1), Card: (6, 3)]],\n","  8: [],\n","  9: [],\n","  10: [[Card: (1, 1), Card: (9, 4)], [Card: (4, 2), Card: (6, 3)]]})"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["test1_SGS.GetScores()"]},{"cell_type":"markdown","metadata":{"id":"o3gtyS9GYQ-V"},"source":["This method outputs a `tuple`, the first element of which is just a computation of the rewards associated with the possible picks or cards to be discarded (discarding a card yields 0 points).\n","\n","The second item is a dictionary of single picks: each of them has the `Rank` as key and the relative `Card` as value.\n","\n","The third item is a dictionary of combinations: all possible `Rank` sums are considered and their value correspond to a list of the lists of cards which summed rank represent the legal combination.\n","\n","Note that all these operations are made by the method by taking into account only the `Table` attribute; the method `ApplyMove` will build on this and bridge the output of this method to create __moves__ with the player's `Hand`.\n","\n","In other words, this method correctly identifies that, looking at the current game scenario, a player could pick a 1, a 4, a 6, a 9, a 5 (1 + 4) and a 10 (by either combining 1 + 9 or 4 + 6).\n","\n","`GetAvailableMoves` is the method that builds a bridge between `GetScores` and `ApplyMove`: a __move__ is defined as a `dict` in which the __key__ represent the card to be played or discarded and the value either the single `Card` to be picked (and removed from the `Table`) or the `list` (combination) of cards."]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":93,"status":"ok","timestamp":1693230361760,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"iX9A-vgMH7-F"},"outputs":[],"source":["test1_AvailableMoves = test1_SGS.GetAvailableMoves()"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93,"status":"ok","timestamp":1693230361760,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"Ah98L9zOH7-G","outputId":"2b2b5bc5-9058-4d10-bcfe-a223194cef5a"},"outputs":[{"data":{"text/plain":["{Card: (1, 2): [Card: (1, 1)],\n"," Card: (10, 4): [[Card: (1, 1), Card: (9, 4)], [Card: (4, 2), Card: (6, 3)]],\n"," Card: (5, 3): [[Card: (1, 1), Card: (4, 2)]]}"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["test1_AvailableMoves"]},{"cell_type":"markdown","metadata":{"id":"2tEHPLT6YQ-W"},"source":["The utility function `unpack_moves` comes into play to iterate among this problematic scenario: what if I can choose between different combinations to be picked with the same card?\n","\n","`dict` keys must be unique, and this makes for a collection of moves which can be hard to iterate upon: as we see in the example, we have a list, a list of lists, and we could also have just a `Card` as the value."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87,"status":"ok","timestamp":1693230361760,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"2vB5eDABYQ-W","outputId":"0be5a88f-a426-4851-8c0e-db50b5bd40fc"},"outputs":[{"data":{"text/plain":["<generator object unpack_moves at 0x11f8d0890>"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["unpack_moves(test1_SGS.GetAvailableMoves())"]},{"cell_type":"markdown","metadata":{"id":"Z0QnOi09YQ-W"},"source":["This function solve this problem by creating a `generator` that, when iterated, yield just a simple dictionary with a `Card` as key and a `Card` or list of `Card`s as value."]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81,"status":"ok","timestamp":1693230361760,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"VBH6m1epH7-H","outputId":"b063ecdb-b229-4d0b-e74f-4d27bf5a96b0"},"outputs":[{"data":{"text/plain":["[{Card: (1, 2): Card: (1, 1)},\n"," {Card: (10, 4): [Card: (1, 1), Card: (9, 4)]},\n"," {Card: (10, 4): [Card: (4, 2), Card: (6, 3)]},\n"," {Card: (5, 3): [Card: (1, 1), Card: (4, 2)]}]"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["list(unpack_moves(test1_AvailableMoves))"]},{"cell_type":"markdown","metadata":{"id":"B_LdxBm7YQ-W"},"source":["If no cards can be taken from the table, these methods works in the same way. Not taking anything is translated as an empty list, which will be the `value` of a dictionary having as `key` the card that the player can discard from its hand."]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76,"status":"ok","timestamp":1693230361760,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"K9p4dmC5Styh","outputId":"a46e0cdf-0f2b-4c1f-f3b1-85cefebee119"},"outputs":[{"name":"stdout","output_type":"stream","text":["PlayerPosition 3\n","PlayersCards {0: [(1, 2), (10, 4), (5, 3)], 1: [(2, 2), (9, 3), (8, 3)], 2: [(1, 1), (9, 2), (4, 3)], 3: [(10, 1), (10, 3), (3, 3), (7, 3)]}\n","Team Deck\n","Hand [(10, 1), (10, 3), (3, 3), (7, 3)]\n","TeamScores {'Hand': 500, 'Deck': 500}\n","Reward 0\n","Table []\n","Deck []\n","LastTaker <NA>\n","ParentMove <NA>\n","values {(1, 1): 26, (2, 1): 22, (3, 1): 23, (4, 1): 24, (5, 1): 25, (6, 1): 28, (7, 1): 139, (8, 1): 20, (9, 1): 20, (10, 1): 139, (1, 2): 16, (2, 2): 12, (3, 2): 13, (4, 2): 14, (5, 2): 15, (6, 2): 18, (7, 2): 29, (8, 2): 10, (9, 2): 10, (10, 2): 10, (1, 3): 16, (2, 3): 12, (3, 3): 13, (4, 3): 14, (5, 3): 15, (6, 3): 18, (7, 3): 29, (8, 3): 10, (9, 3): 10, (10, 3): 10, (1, 4): 16, (2, 4): 12, (3, 4): 13, (4, 4): 14, (5, 4): 15, (6, 4): 18, (7, 4): 29, (8, 4): 10, (9, 4): 10, (10, 4): 10}\n"]}],"source":["test3_SGS = ScoponeGameState(\n","    PlayerPosition=test3_PlayerPosition,\n","    PlayersCards=test3_PlayersCards,\n","    Team=test3_Team,\n","    TeamScores=test3_TeamScores,\n","    Table=test3_Table\n",")\n","print_attributes(test3_SGS)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"txGqebDuStyh","outputId":"bd5b1013-99f9-4986-f897-8b1900867b59"},"outputs":[{"data":{"text/plain":["{Card: (10, 1): [], Card: (10, 3): [], Card: (3, 3): [], Card: (7, 3): []}"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["test3_SGS.GetAvailableMoves()"]},{"cell_type":"markdown","metadata":{"id":"s0nSJKcwH7-I"},"source":["#### `ApplyMove`\n","\n","`ApplyMove` is the __workhorse__ method in the creation of a simulated game: taking as input a move, chosen systematically or at random, it __applies__ it by modifying:\n","\n","- the player's `Hand`: the played card is removed.\n","- the `Table` for all players: if there is a pick to be made, the corresponding single card or set is removed.\n","- the `Team` score: the team is awarded a reward, which will be either\n","    - Positive: if the points are taken by the player or its team mate.\n","    - Negative: if the points are taken by either one of the other players.\n","\n","A quick reminder of the current game state, `test_1`:"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"Jb8O9X_JYQ-X","outputId":"b67ed143-3019-46cc-a682-ba681efea9b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["###\n","ScoponeGameState:\n","###\n",">Parent Move: <NA>.\n","> Current hand: [(1, 2), (10, 4), (5, 3)]\n","> Current table: [(1, 1), (4, 2), (9, 4), (6, 3)]\n","> Points: {'Hand': 500, 'Deck': 500}\n","The reward for this State is: 0.\n","###\n"]}],"source":["print(test1_SGS)"]},{"cell_type":"markdown","metadata":{"id":"TskctK3pYQ-X"},"source":["As an example, we imagine that the AI player wants to take the __9 of Bastoni__ (9, 4) and the __1 or Ori__ (1, 1) with the __10 of Bastoni__:"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":58,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"B1Dk42nTH7-I"},"outputs":[],"source":["test1_BestMove = {Card(10, 4): [Card(9, 4), Card(1, 1)]}\n","\n","test1_modified = test1_SGS.ApplyMove(test1_BestMove)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"l80bAKA-YQ-X","outputId":"72caf922-cd7c-4caa-fb28-8ff6296bfa39"},"outputs":[{"name":"stdout","output_type":"stream","text":["###\n","ScoponeGameState:\n","###\n",">Parent Move: <NA>.\n","> Current hand: [Card: (1, 2), Card: (5, 3)]\n","> Current table: [(4, 2), (6, 3)]\n","> Points: {'Hand': 546, 'Deck': 500}\n","The reward for this State is: 46.\n","###\n"]}],"source":["print(test1_modified)"]},{"cell_type":"markdown","metadata":{"id":"zHdkf-59YQ-X"},"source":["As we can see, the method __modified__ the `ScoponeGameState`, leading to another __node__ in the game tree.\n","\n","Both the _hand_ and _table_ have been updated by removing all the corresponding cards; the scores have been awarded to the team to which the player belongs.\n","\n","If no pick is available:"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"t8fUlGHMUJoJ","outputId":"b95072fe-7569-468d-80a6-01c4275e6ed5"},"outputs":[{"data":{"text/plain":["###\n","ScoponeGameState:\n","###\n",">Parent Move: <NA>.\n","> Current hand: [(10, 1), (10, 3), (3, 3)]\n","> Current table: [(7, 3)]\n","> Points: {'Hand': 500, 'Deck': 500}\n","The reward for this State is: 0.\n","###"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["test3_SGS.ApplyMove(\n","        {(7, 3): []}\n","    )"]},{"cell_type":"markdown","metadata":{"id":"HPkukuU9YQ-Y"},"source":["Only the `Hand` attribute is modified. While this is also a _node_, no points are awarded.\n","\n","Note that the `ParentMove` attribute is not updated: this will be the task assigned to another class, because `ApplyMove` is used with moves originated by different algorithms, both the rule-based simulated players and the MCTS; however, we are only interested in the move made by the MCTS agent for the __backpropagation__ algorithm; therefore, `ParentMove` will be updated elsewhere."]},{"cell_type":"markdown","metadata":{"id":"FBa39VuOH7-I"},"source":["#### `FindChildren`\n","\n","The Monte Carlo algorithm performs a search among all the branches of a game tree. If a `ScoponeGameState` is a computational representation of a __node__, it will branch out generating a number of `Children`: each of these is a new `ScoponeGameState`, created by computing and simulating the consequences of playing one among the possible moves in that given scenario.\n","\n","The possible moves to be made in the game state `test1` are:"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"EisXByWpYQ-Y","outputId":"cda14608-da88-49cd-fed8-766973467fb0"},"outputs":[{"data":{"text/plain":["[{Card: (1, 2): Card: (1, 1)},\n"," {Card: (10, 4): [Card: (1, 1), Card: (9, 4)]},\n"," {Card: (10, 4): [Card: (4, 2), Card: (6, 3)]},\n"," {Card: (5, 3): [Card: (1, 1), Card: (4, 2)]}]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["list(unpack_moves(test1_AvailableMoves))"]},{"cell_type":"markdown","metadata":{"id":"QbpehCFVYQ-Y"},"source":["Each one of them can be conceptualised as the `Parent` node of a `Children` node: `FindChilden` is the method that finds them and creates a list of the resulting game states."]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"O2uFKN9yH7-J"},"outputs":[],"source":["\n","test1_childrens = test1_SGS.FindChildren()"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"wSrAei3NQwhD","outputId":"303d4d22-8497-4e43-be4e-6dd761b705f2"},"outputs":[{"data":{"text/plain":["[###\n"," ScoponeGameState:\n"," ###\n"," >Parent Move: {Card: (1, 2): Card: (1, 1)}.\n"," > Current hand: [Card: (10, 4), Card: (5, 3)]\n"," > Current table: [(4, 2), (9, 4), (6, 3)]\n"," > Points: {'Hand': 542, 'Deck': 500}\n"," The reward for this State is: 42.\n"," ###,\n"," ###\n"," ScoponeGameState:\n"," ###\n"," >Parent Move: {Card: (10, 4): [Card: (1, 1), Card: (9, 4)]}.\n"," > Current hand: [Card: (1, 2), Card: (5, 3)]\n"," > Current table: [(4, 2), (6, 3)]\n"," > Points: {'Hand': 546, 'Deck': 500}\n"," The reward for this State is: 46.\n"," ###,\n"," ###\n"," ScoponeGameState:\n"," ###\n"," >Parent Move: {Card: (10, 4): [Card: (4, 2), Card: (6, 3)]}.\n"," > Current hand: [Card: (1, 2), Card: (5, 3)]\n"," > Current table: [(1, 1), (9, 4)]\n"," > Points: {'Hand': 542, 'Deck': 500}\n"," The reward for this State is: 42.\n"," ###,\n"," ###\n"," ScoponeGameState:\n"," ###\n"," >Parent Move: {Card: (5, 3): [Card: (1, 1), Card: (4, 2)]}.\n"," > Current hand: [Card: (1, 2), Card: (10, 4)]\n"," > Current table: [(9, 4), (6, 3)]\n"," > Points: {'Hand': 555, 'Deck': 500}\n"," The reward for this State is: 55.\n"," ###]"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["test1_childrens"]},{"cell_type":"markdown","metadata":{"id":"R4CIBIW1YQ-Y"},"source":["`FindChildren`, moreover, being the fundamental building block of the MCTS, is only used in that setting: as we can see, now also the `ParentMove` attribute is updated. This allows us to keep track of the sequence (path) composing a branch."]},{"cell_type":"markdown","metadata":{"id":"Xg_dbHVCQwhD"},"source":["#### `FindRandomChildren`\n","\n","However, finding __all__ the possible childrens is not enough: the Monte Carlo method is __simulation__ based. To perform a rollout, to fully explore a brach, it needs to __randomly__ select a _children: this allows us to obtain a simplified tree, in which each node does not lead to multiple branches because every time a random choice is made to rollout only a single possible path."]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"aXrErzOBQwhD","outputId":"df0dd0c0-b8d5-4fb5-bd63-143642893b29"},"outputs":[{"data":{"text/plain":["###\n","ScoponeGameState:\n","###\n",">Parent Move: {Card: (10, 4): [Card: (1, 1), Card: (9, 4)]}.\n","> Current hand: [Card: (1, 2), Card: (5, 3)]\n","> Current table: [(4, 2), (6, 3)]\n","> Points: {'Hand': 546, 'Deck': 500}\n","The reward for this State is: 46.\n","###"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["test1_SGS.FindRandomChildren()"]},{"cell_type":"markdown","metadata":{"id":"iiTT_9orH7-J"},"source":["## `MCTS`\n","\n","> __DISCLAIMER__: from this point onward, the mental stability of the coders was severely depleted, causing a 56.783% decrease in the level of seriousness.\n","\n","The `ScoponeMove` and `ScoponeGameState` classes are the two main ingredients from which an AI player can:\n","\n","- Store and retrieve all the information needed to computationally represent a game scenario at any given time.\n","- Modifiy this scenario by exploring the possible ramifications of either its moves and the reasonable opponents' and team members strategies.\n","\n","The last missing item is a _pot_, another container that implements the Monte Carlo Tree seach by mixing together these ingredients, adding all the necessary tools and routines to make everything work together.\n","\n","We created a __MCTS _agent___, which is instantiated with the `ScoponeGameState` it is facing and shall output the _best_ move, according to its simulated scenario.\n","\n","We will call it `AgentCarletto` and he has a single purpose: to beat you at Scopone."]},{"cell_type":"markdown","metadata":{"id":"D2V7z5eCUJoK"},"source":["### Code"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"W_5XW1mfUJoK"},"outputs":[],"source":["\n","class AgentCarletto(object):\n","    \"\"\"\n","    This class represents a MonteCarlo Agent, which simulates a game-tree starting from\n","    a given ScoponeGameState.\n","\n","    It contains methods to:\n","\n","    - check whether the attributes have been correctly stored.\n","    - simulate a whole turn with all the other players' move.\n","    - expand a node by considering all the possible moves and the other players' reactions.\n","    - perform a complete rollout and backpropagate the corresponding parent move and its reward in the final\n","    state of the game.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        CurrentGameState: ScoponeGameState,\n","        ComputationalBudget: int = 500\n","        ) -> None:\n","        \"\"\"\n","\n","        Args:\n","            CurrentGameState (ScoponeGameState): a ScoponeGameState representing the current game in all its aspects, because\n","                AgentCarletto needs to know what is doing.\n","            ComputationalBudget (int, optional): the MCTS algorithm is simulation based; it will explore single branches until a computational budget is exausted.\n","                Defaults to 100. Higher budgets might lead to a significant slowdown.\n","        \"\"\"\n","\n","        self.CurrentGameState = CurrentGameState\n","        self.ComputationalBudget = ComputationalBudget\n","\n","    # def __new__(\n","    #     cls, *args, **kwargs\n","    # ):\n","    #     newagent = \"It's A Me, Carletto!\"\n","    #     print(newagent)\n","    #     return super().__new__(cls)\n","\n","    def __repr__(self) -> str:\n","        BadAssIntro = \"Hi, my name is Carletto.\" + \" I'm here to kick your ass at Scopone and chew bubble gum.\" + \" And I'm all outta bubble gum.\"\n","        return BadAssIntro\n","\n","    def TurnChecker(\n","        self,\n","        CurrentGameState: ScoponeGameState\n","    ) -> None:\n","        \"\"\"\n","        This function checks that the player starting at a given turn is assigned to the correct team;\n","        if not, it corrects the assignment.\n","\n","        Args:\n","            CurrentGameState (ScoponeGameState): a ScoponeGameState to be checked.\n","        \"\"\"\n","        turn = CurrentGameState.PlayerPosition\n","\n","        if turn == 0 or turn == 2:\n","            CurrentGameState.Team = \"Hand\"\n","        elif turn == 1 or turn == 3:\n","            CurrentGameState.Team = \"Deck\"\n","\n","    def SimulateTurn(self) -> ScoponeGameState:\n","        \"\"\"\n","        This function simulates all the player's turns. It takes as an input a ScoponeGameState,\n","        in which the MCTS agent has already made a move.\n","\n","        Returns:\n","            ScoponeGameState: a ScoponeGameState resulting from all the players'moves.\n","        \"\"\"\n","\n","        ClonedCurrentGameState = self.CurrentGameState.CloneState()\n","\n","        if ClonedCurrentGameState.PlayerPosition == 0:\n","            turns = range(ClonedCurrentGameState.PlayerPosition + 1, ClonedCurrentGameState.PlayerPosition + 4)\n","        else:\n","            turns = range(ClonedCurrentGameState.PlayerPosition % 1, ClonedCurrentGameState.PlayerPosition % 4)\n","\n","        for turn in turns:\n","            ClonedCurrentGameState.PlayerPosition = turn\n","            if turn == 0 or turn == 2:\n","                ClonedCurrentGameState.Team = \"Hand\"\n","            elif turn == 1 or turn == 3:\n","                ClonedCurrentGameState.Team = \"Deck\"\n","\n","            ClonedCurrentGameState.Hand = ClonedCurrentGameState.PlayersCards[turn]\n","\n","            try:\n","                ClonedCurrentGameState = ClonedCurrentGameState.ApplyMove(\n","                    ScoponeMove(\n","                        LegalMoves=ClonedCurrentGameState.Hand,\n","                        Table=ClonedCurrentGameState.Table,\n","                    ).GetMove(\n","                        Greedy=True,\n","                        Standalone=False\n","                    )\n","                )\n","            except:\n","                pass\n","\n","        ClonedCurrentGameState.PlayerPosition = self.CurrentGameState.PlayerPosition\n","        ClonedCurrentGameState.Team = self.CurrentGameState.Team\n","        ClonedCurrentGameState.Hand = ClonedCurrentGameState.PlayersCards[ClonedCurrentGameState.PlayerPosition]\n","        ClonedCurrentGameState.Reward = ClonedCurrentGameState.ComputeRewards()\n","\n","\n","        return ClonedCurrentGameState\n","\n","    def Expand(self):\n","        \"\"\"\n","        Expand your CarlettoAgent consciousness and search the Tree.\n","\n","        This method takes all the possible moves and simulate the consequence of playing them,\n","        updating the GameState and moving the tree one step further down a given branch.\n","        It is used as a starter, to evaluate all the possible strategies when the Agent needs to play.\n","        \"\"\"\n","\n","        ClonedCurrentGameState = self.CurrentGameState.CloneState()\n","        self.TurnChecker(ClonedCurrentGameState)\n","\n","        #@@@@@@@@@ GENERATING NEW CHILDREN @@@@@@@@@@#\n","\n","        possible_moves_list = ClonedCurrentGameState.FindChildren()\n","\n","        resulting_game_states = list()\n","\n","        for move in possible_moves_list:\n","\n","            ############ SELECTING NEW CHILDREN ############\n","\n","            try:\n","                updated_game_state = AgentCarletto(move).SimulateTurn()\n","                updated_game_state.ParentMove = move\n","                resulting_game_states.append(updated_game_state)\n","            except TypeError:\n","                EndGame = \"We're in the EndGame now..\"\n","                print(EndGame)\n","                break\n","\n","        return resulting_game_states\n","\n","    def Simulate(self) -> tuple:\n","        \"\"\"\n","        This methods performs the rollout (simulate a game until the end)\n","        and backpropagation (computes the final scores, their rewards and maps them to the origin of the branch,\n","        and the path).\n","\n","        Returns:\n","            tuple:\n","                - a dict with the simulated game state that started the branch and the reward of the finished game.\n","                - a list with all the nodes in the sequence, representing the complete branch.\n","        \"\"\"\n","\n","        Simulation = dict()\n","        TotalReward = 0\n","        Path = list()\n","        TablePoints = 0\n","\n","        ExpandedGameState = self.CurrentGameState.CloneState()\n","        counter = 0\n","\n","        while not ExpandedGameState.IsTerminal():\n","            ExpandedGameState = ExpandedGameState.FindRandomChildren()\n","            ExpandedGameState = AgentCarletto(ExpandedGameState).SimulateTurn()\n","            if counter == 0:\n","                Simulation = ExpandedGameState\n","                Path.append(ExpandedGameState)\n","            else:\n","                TotalReward = ExpandedGameState.Reward\n","                Path.append(ExpandedGameState)\n","            counter += 1\n","\n","        ### This code block is used to compute the reward in the last turn.\n","\n","        if ExpandedGameState.IsTerminal():\n","            if isinstance(ExpandedGameState.LastTaker, NAType):\n","                TakeAllTeam = \"Deck\"\n","            elif ExpandedGameState.LastTaker == 0 or ExpandedGameState.LastTaker == 2:\n","                TakeAllTeam = \"Hand\"\n","            elif ExpandedGameState.LastTaker == 1 or ExpandedGameState.LastTaker == 3:\n","                TakeAllTeam = \"Deck\"\n","\n","            for leftover in ExpandedGameState.Table:\n","                TablePoints += convert_to_card(leftover).Value()\n","\n","            ExpandedGameState.TeamScores[TakeAllTeam] += TablePoints\n","            ExpandedGameState.Reward = ExpandedGameState.ComputeRewards()\n","\n","\n","        return {Simulation:TotalReward}, Path\n","\n","    def TreeSearch(self) -> dict:\n","        \"\"\"\n","        This method performs the Monte Carlo Tree Search for our Agent and outputs the\n","        resulting best move.\n","\n","        Returns:\n","            dict: a game move {card to be played: card/s to be taken}.\n","        \"\"\"\n","\n","        maxBudget = self.ComputationalBudget\n","\n","        Parents = self.Expand()\n","        BestMove = {key: 0 for key in Parents}\n","\n","        Simulation, Path = self.Simulate()\n","\n","        while maxBudget > 0:\n","            NeoSimulation, NeoPath = self.Simulate()\n","            for State in Simulation.keys():\n","                for NeoState in NeoSimulation.keys():\n","                    # No need to explore already seen branches.\n","                    if Path != NeoPath:\n","                        if State == NeoState:\n","                            BestMove[State] = max(Simulation[State], NeoSimulation[NeoState])\n","                        elif State != NeoState:\n","                            if Simulation[State] < NeoSimulation[NeoState]:\n","                                BestMove[NeoState] = NeoSimulation[NeoState]\n","\n","            maxBudget -= 1\n","\n","        # points = BestMove[max(BestMove, key=BestMove.get)]\n","        BestMove = max(BestMove, key=BestMove.get)\n","        BestMove = BestMove.ParentMove\n","\n","\n","        return BestMove.ParentMove"]},{"cell_type":"markdown","metadata":{"id":"xjy4J0MvStym"},"source":["---\n","\n","### Test\n","\n","Testing whether the MCTS agent is performing as expected is tricky.\n","\n","On the one hand, it is often impossible (as in really expensive) to analyse and visualize the whole tree, making it a viable option only for scenarios involving the last parts of the game. The slides include a diagram for `test_1`, in which it is easy to recognise which is the optimal move among the possibilities.\n","\n","On the other hand, the algorithm is __simulation-based__: it is not expected that the __best move__ will be the output, as we are expecting the best move __among the simulated scenarios__, given the __computational budget__. In other words, the tree search does not span the whole tree and there is a random approach to the exploration, as different moves are tried bringing to different rollouts and paths.\n","\n","Reinforment learning methods come into play in our implementation because we decided to use a __policy__ approach to determine the best option. Given a set of nodes, characterised by an action $a$ (`ParentMove`, the move that generated a node) and the state $s$ deriving from that action, being $R(a)$ the reward associated with that state the decision function can be espressed as:\n","$$\n","Q(a, s) = \\underbrace{ R(s) }_{\\mathrm{Return \\ you \\ get \\ right \\ away}}  + \\underbrace{ \\max_{a'} Q(s', a') }_{\\mathrm{Return \\ from \\ behaving \\ optimally \\ starting \\ from \\ state} s'}\n","$$\n","\n","\n","Rewards are either negative or positive, to learn the correct strategy among the possibilites.\n","We are considering two components:\n","\n","- First, we need to understand whichever are the consequence of the available actions at a given state (playing a card, simulating the other players' strategies).\n","- Second, we need to choose the best option, given the assumptions that all the players behave optimally after that.\n","\n","However, this second part would entail to explore _the whole tree_, with a great expense of resources: this is where `FindRandomChild` comes into play, using the Monte Carlo Tree Search algorithm to greatly simplify the search, sparing resources. This means that it is not actually the _optimal_ strategy that we are using to perform the search among the possible game states: we are using a __logical__, __rule-based__ approach (in particular, throught the `Greedy` or `Intermediate` AIs).\n","\n","The main implication is that __the algorithm is not guaranteed__ to return __the absolute best__, as chance might lead to never explore that path. However, this approach leads to a consistenly realistic adversary, powered by an AI that, while it does not wins _always_, it does not spoil the fun by being an ominscent and unbeatable player."]},{"cell_type":"markdown","metadata":{"id":"ZMvIflRMStym"},"source":["#### Carletto\n","\n","All the MCTS methods and data are stored inside the `AgentCarletto` class. To instantiate this AI player, a `ScoponeGameState` is needed, as it contains all the information required.\n","\n","Note that the MCTS is very information intensive: it is an __omniscent__ player, which knows also every other player's card. This is a necessary step that allows to simulate their reaction to all the possible actions."]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"RpkPw32XUJoL"},"outputs":[],"source":["Carletto = AgentCarletto(test1_SGS)"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"BG8ntHewYQ-Z","outputId":"73af694b-71cb-4076-8032-f8a2ddf85ab9"},"outputs":[{"data":{"text/plain":["Hi, my name is Carletto. I'm here to kick your ass at Scopone and chew bubble gum. And I'm all outta bubble gum."]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["Carletto"]},{"cell_type":"markdown","metadata":{"id":"lOk975BpYQ-a"},"source":["##### `Expand`\n","\n","The `Expand` method takes the starting node, finds all its possible childrens and returns the resulting game states with their reward $R(a)$.\n","\n","In other words, the following list of game states represents all the consequences of the possible agent's actions at a given turn."]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1693230361761,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"soQetb4ZUJoL","outputId":"f760e8db-ca76-4f20-bf0b-5d05f11019ff"},"outputs":[{"data":{"text/plain":["[###\n"," ScoponeGameState:\n"," ###\n"," >Parent State: {Card: (1, 2): Card: (1, 1)}.\n"," > Current hand: [Card: (10, 4), Card: (5, 3)]\n"," > Current table: [(4, 2), (9, 4), (6, 3)]\n"," > Points: {'Hand': 542, 'Deck': 500}\n"," The reward for this State is: 42.\n"," ###,\n"," ###\n"," ScoponeGameState:\n"," ###\n"," >Parent State: {Card: (10, 4): [Card: (1, 1), Card: (9, 4)]}.\n"," > Current hand: [Card: (1, 2), Card: (5, 3)]\n"," > Current table: [(4, 2), (6, 3)]\n"," > Points: {'Hand': 546, 'Deck': 500}\n"," The reward for this State is: 46.\n"," ###,\n"," ###\n"," ScoponeGameState:\n"," ###\n"," >Parent State: {Card: (10, 4): [Card: (4, 2), Card: (6, 3)]}.\n"," > Current hand: [Card: (1, 2), Card: (5, 3)]\n"," > Current table: [(1, 1), (9, 4)]\n"," > Points: {'Hand': 542, 'Deck': 500}\n"," The reward for this State is: 42.\n"," ###,\n"," ###\n"," ScoponeGameState:\n"," ###\n"," >Parent State: {Card: (5, 3): [Card: (1, 1), Card: (4, 2)]}.\n"," > Current hand: [Card: (1, 2), Card: (10, 4)]\n"," > Current table: [(9, 4), (6, 3)]\n"," > Points: {'Hand': 555, 'Deck': 500}\n"," The reward for this State is: 55.\n"," ###]"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["Carletto.Expand()"]},{"cell_type":"markdown","metadata":{"id":"hX_Md5HTYQ-a"},"source":["##### `SimulateTurn`\n","\n","This method then advances the game by _simulating the other player's reactions_, under the assumption that everyone behaves optimally; in our case, all the other player are simulated by using rule-based AI algorithms."]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1693230361762,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"R0AvVx91YQ-a","outputId":"2e4fdf09-6a3e-4f26-b2cb-91f81392caac"},"outputs":[{"data":{"text/plain":["###\n","ScoponeGameState:\n","###\n",">Parent Move: <NA>.\n","> Current hand: [(1, 2), (10, 4), (5, 3)]\n","> Current table: []\n","> Points: {'Hand': 542, 'Deck': 1691}\n","The reward for this State is: -1149.\n","###"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["Carletto.SimulateTurn()"]},{"cell_type":"markdown","metadata":{"id":"qqGHJAreYQ-a"},"source":["In this case, the example makes it clear why not thinking ahead, as the other functions do, can be a major source of headaches in a game. `Carletto`'s move allowed a _scopa_ for the other team."]},{"cell_type":"markdown","metadata":{"id":"8m-ts0gkYQ-a"},"source":["##### `Simulate`\n","\n","This is the method that performs both the __rollout__. Building upon the _expanded_ original game scenario and all the other players' reactions, it fully explores a _branch_ by __randomly selecting__ a possible move at each subsequent node, while at the same time keeping track of the _score_."]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1693230361762,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"9s7DQhcrQwhF","outputId":"91bb4a24-c028-4337-bdca-5e6b129d1a01"},"outputs":[{"data":{"text/plain":["({###\n","  ScoponeGameState:\n","  ###\n","  >Parent Move: {Card: (1, 2): Card: (1, 1)}.\n","  > Current hand: [(10, 4), (5, 3)]\n","  > Current table: [(6, 3), (10, 3)]\n","  > Points: {'Hand': 570, 'Deck': 520}\n","  The reward for this State is: 50.\n","  ###: -140},\n"," [###\n","  ScoponeGameState:\n","  ###\n","  >Parent Move: {Card: (1, 2): Card: (1, 1)}.\n","  > Current hand: [(10, 4), (5, 3)]\n","  > Current table: [(6, 3), (10, 3)]\n","  > Points: {'Hand': 570, 'Deck': 520}\n","  The reward for this State is: 50.\n","  ###,\n","  ###\n","  ScoponeGameState:\n","  ###\n","  >Parent Move: {Card: (5, 3): []}.\n","  > Current hand: [(10, 4)]\n","  > Current table: [(6, 3), (5, 3), (8, 3), (9, 2)]\n","  > Points: {'Hand': 570, 'Deck': 669}\n","  The reward for this State is: -99.\n","  ###,\n","  ###\n","  ScoponeGameState:\n","  ###\n","  >Parent Move: {Card: (10, 4): []}.\n","  > Current hand: []\n","  > Current table: [(6, 3), (5, 3), (8, 3), (9, 2), (10, 4)]\n","  > Points: {'Hand': 633, 'Deck': 710}\n","  The reward for this State is: -77.\n","  ###])"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["Carletto.Simulate()"]},{"cell_type":"markdown","metadata":{"id":"iC8y1uI3YQ-a"},"source":["This succession of game states is therefore a __fully developed branch__, in which one among the expanded _children_ of the initial game state is developed until the game is finished, creating a `Path` of linked `ScoponeGameStates`.\n","\n","Note that for each game state $s$ the algorithm computes $a$ (`ParentMove`) and $R(s)$ (`Reward`)."]},{"cell_type":"markdown","metadata":{"id":"mWUKC3IoYQ-a"},"source":["##### `TreeSearch`\n","\n","All the previous methods are then combined in the `TreeSearch`: until a given `ComputationalBudget` is depleted, games are simulated. The original move is stored and brought forward, until a terminal state is not reached (there are no more cards to be played, all hands are empty).\n","\n","Then, both this _original move_ and the _reward_ achieved at the end of the game are _propagated backward_ and stored; new simulations are made and at every simulation their reward are compared, with only the best choice kept as the optimal move.\n","\n","This implements the second part of the fundamental computation that allows the AI to __learn__ what is the optimal move through an iterative search of the tree with the Monte Carlo method, and this move will be the output of this method, which is the only one that needs to be called to use the algorithm in a game."]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2330,"status":"ok","timestamp":1693230364083,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"4A4-Tva1YQ-a","outputId":"e7223fbf-ac32-4efc-f596-953257a14a06"},"outputs":[{"data":{"text/plain":["{Card: (1, 2): Card: (1, 1)}"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["Carletto.TreeSearch()"]},{"cell_type":"markdown","metadata":{"id":"1YxMqkvQYQ-b"},"source":["The performance, at a computational budget of 500 (number of simulation runs), makes it more than usable inside a program."]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26522,"status":"ok","timestamp":1693230390595,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"1q6X0HUpYQ-b","outputId":"49dd788a-0c85-48ac-8300-e87db09976f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.04 s ± 8.47 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}],"source":["%timeit Carletto.TreeSearch()"]},{"cell_type":"markdown","metadata":{"id":"kgFSRPgyStyn"},"source":["#### Carletto III"]},{"cell_type":"code","execution_count":68,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1693230390595,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"ho6TNN0kStyn"},"outputs":[],"source":["AgentCarlettoTheThird = AgentCarletto(test3_SGS)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3181,"status":"ok","timestamp":1693230393767,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"t2n8DbQyYQ-b","outputId":"7c998dc7-c4a2-4de3-bacc-4443e033da78"},"outputs":[{"data":{"text/plain":["{Card: (3, 3): []}"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["AgentCarlettoTheThird.TreeSearch()"]},{"cell_type":"markdown","metadata":{"id":"wvLhsECuYQ-b"},"source":["##### BigCarletto\n","\n","In this scenario, we are considering a game that has just started, to compare the performance with a tree of maximum extension."]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1693230393767,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"mb-dm_ooYQ-b"},"outputs":[],"source":["ft_PlayerPosition = 0\n","ft_PlayerCards = {\n","    0:\n","    [\n","        (8, 2),\n","        (8, 4),\n","        (5, 2),\n","        (10, 3),\n","        (7, 4),\n","        (4, 1),\n","        (1, 2),\n","        (10, 1),\n","        (9, 1),\n","        (6, 2)\n","    ],\n","    1:\n","    [\n","        (1, 3),\n","        (4, 4),\n","        (8, 3),\n","        (7, 1),\n","        (6, 3),\n","        (7, 3),\n","        (1, 4),\n","        (2, 3),\n","        (4, 2),\n","        (2, 2)\n","    ],\n","    2:\n","    [\n","        (9, 2),\n","        (10, 2),\n","        (6, 1),\n","        (10, 4),\n","        (5, 4),\n","        (3, 4),\n","        (2, 4),\n","        (3, 3),\n","        (9, 4),\n","        (8, 1)\n","    ],\n","    3:\n","    [\n","        (1, 1),\n","        (2, 1),\n","        (3, 1),\n","        (7, 2),\n","        (5, 3),\n","        (3, 2),\n","        (9, 3),\n","        (4, 3),\n","        (5, 1),\n","        (6, 4)\n","    ]\n","}\n","ft_Team = \"Hand\"\n","ft_TeamScores = {\n","    \"Hand\": 0,\n","    \"Deck\": 0\n","}"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1693230393767,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"2TKnO8CyYQ-b"},"outputs":[],"source":["final_test = ScoponeGameState(\n","    ft_PlayerPosition,\n","    ft_PlayerCards,\n","    ft_Team,\n","    ft_TeamScores\n",")"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1693230393767,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"AB5kJ89sYQ-b"},"outputs":[],"source":["BigCarletto = AgentCarletto(final_test)"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16337,"status":"ok","timestamp":1693230410094,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"y4AU6J1JYQ-b","outputId":"73df655b-e1f8-4279-b6e5-6480e4bf2f90"},"outputs":[{"data":{"text/plain":["{Card: (4, 1): []}"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["BigCarletto.TreeSearch()"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11157,"status":"ok","timestamp":1693230538931,"user":{"displayName":"Marco Solari","userId":"15568246660325140449"},"user_tz":-120},"id":"kb1_G6DqYQ-c","outputId":"f05354d4-feef-43d5-982b-199f615e29aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["5.63 s ± 31.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}],"source":["%timeit BigCarletto.TreeSearch()"]},{"cell_type":"markdown","metadata":{"id":"oFo2QeevYQ-c"},"source":["As a concluding remark, there is an important trade-off here to be considered between __computational resources__ and __performance__. The probability of reaching the absolute optimum and therefore returning the absolute best move is increasing in the number of simulations; however, this could potentially slow down the performance excessively while being only partially useful: as the game progresses, the possible paths shrink, making a high number of simulations much less useful to reach a good solution. Moreover, all the game needs to be simulated again __at every turn__, because the assumption that everyone plays optimally or actually follows a `Greedy` strategy is only useful as a simulation technique, while the algorithm needs to react to the actual scenario generated after it has returned a move to be effective, waiting for the other players; this means that a __full exploration of the tree__ is not a reasonable strategy, as demonstrated by the worse performance of `MinMax` algorithms in a game setting (Di Palma, 2014).\n","\n","The __simulation-based Monte Carlo__, mixed with a __reinforcement learning approach to move selection__, yields a intrinsically random output that actually allows for a better AI player, more challenging than rule-based AI while not being unbeatable and, therefore, not fun."]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
